{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOUjUE7dLlU9Y4Lmv4ZDTk9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hugoalfedoputra-ub/ml/blob/main/nn_practice/JST_CH3_Hugo_Alfedo_Putra_225150201111013.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "vRCF5Ncb0wJo"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "INT_MAX = 2147483647\n",
        "\n",
        "data = [\n",
        "    [1,1,1,1],\n",
        "    [-1,1,-1,-1],\n",
        "    [1,1,1,-1],\n",
        "    [1,-1,-1,1]\n",
        "]\n",
        "\n",
        "target = [1,1,-1,-1]\n",
        "\n",
        "lr = 1\n",
        "ones = np.ones((4,1))\n",
        "\n",
        "dataset = np.hstack((data, ones))\n",
        "\n",
        "w = [0 for _ in range(len(dataset[0]))]\n",
        "\n",
        "# Slides FILKOM pakai bipolar step function\n",
        "def bip_step(net, th=0):\n",
        "  if net > th:\n",
        "    return 1\n",
        "  elif -1*th <= net and net <= th:\n",
        "    return 0\n",
        "  else:\n",
        "    return -1\n",
        "\n",
        "# Wikipedia pakai Heaviside step-function (unit step function)\n",
        "def bin_step(net, th=0):\n",
        "  return 1 if net>=th else 0\n",
        "\n",
        "def perceptron(data, target, init, lr=1e-1, delta_rule='filkom', activation=bip_step, stop_early=False, th=0, stop=1e-3):\n",
        "  # delta can be 'filkom' or otherwise (e.g. 'wiki')\n",
        "  prev = [INT_MAX for _ in range(len(data[0]))]\n",
        "  epoch = 0\n",
        "  validity = [False for i in range(len(data))]\n",
        "  # print(init)\n",
        "  while epoch < 10:\n",
        "    if stop_early and (np.max(np.absolute(np.subtract(init, prev))) < stop or all(validity)):\n",
        "      break\n",
        "    prev = init\n",
        "    for i, row in enumerate(data):\n",
        "      net = np.dot(row, init)\n",
        "      f_net = activation(net, th)\n",
        "      # Check if the f_net is the same as target\n",
        "      validity[i] = True if f_net == target[i] else False\n",
        "      delta = [lr * target[i] * row if f_net != target[i] else 0] if delta_rule=='filkom' else [lr * (target[i]-net) * row]\n",
        "      # Adds the new delta values to the current values\n",
        "      init = np.add(init, delta)\n",
        "      # Fixes issues with delta being an array inside an array\n",
        "      init = init[0] if type(delta[0]) == np.ndarray else init\n",
        "    # Increment epoch\n",
        "    epoch += 1\n",
        "    # Reset validity every epoch\n",
        "    validity = [False for i in range(len(data))]\n",
        "    # print(init)\n",
        "\n",
        "  return init, epoch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Keempat hasil berikut menggunakan delta rule berdasarkan slides FILKOM dan juga berdasarkan Wikipedia (https://en.wikipedia.org/wiki/Perceptron).\n",
        "\n",
        "Digunakan pula bipolar step function dan binary step function atau dikenal sebagai hstep seperti pada sumber ini: https://en.wikipedia.org/wiki/Heaviside_step_function."
      ],
      "metadata": {
        "id": "-tpebQ8wH7rz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model1, epoch = perceptron(dataset, target, w, lr, delta_rule='filkom')\n",
        "print(\"Cara: filkom, aktivasi: bipolar step\")\n",
        "print('w1, w2, w3, w4 =\\n', model1[:-1], '\\ndan b =', model1[-1], '\\ndalam', epoch, 'epoch\\n')\n",
        "\n",
        "model2, epoch = perceptron(dataset, target, w, lr, delta_rule='wiki')\n",
        "print(\"Cara: wikipedia, aktivasi: bipolar step\")\n",
        "print('w1, w2, w3, w4 =\\n', model2[:-1], '\\ndan b =', model2[-1], '\\ndalam', epoch, 'epoch\\n')\n",
        "\n",
        "model3, epoch = perceptron(dataset, target, w, lr, delta_rule='filkom', activation=bin_step)\n",
        "print(\"Cara: filkom, aktivasi: binary step (hstep)\")\n",
        "print('w1, w2, w3, w4 =\\n', model3[:-1], '\\ndan b =', model3[-1], '\\ndalam', epoch, 'epoch\\n')\n",
        "\n",
        "model4, epoch = perceptron(dataset, target, w, lr, delta_rule='wiki', activation=bin_step)\n",
        "print(\"Cara: wikipedia, aktivasi: binary step (hstep)\")\n",
        "print('w1, w2, w3, w4 =\\n', model4[:-1], '\\ndan b =', model4[-1], '\\ndalam', epoch, 'epoch\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dO27KnteHuHg",
        "outputId": "cd9ea09f-e75d-441f-c92a-9dc922e54242"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cara: filkom, aktivasi: bipolar step\n",
            "w1, w2, w3, w4 =\n",
            " [-2.  2.  0.  2.] \n",
            "dan b = 0.0 \n",
            "dalam 10 epoch\n",
            "\n",
            "Cara: wikipedia, aktivasi: bipolar step\n",
            "w1, w2, w3, w4 =\n",
            " [26831791. -5728393.  3230775. -5952169.] \n",
            "dan b = 17872623.0 \n",
            "dalam 10 epoch\n",
            "\n",
            "Cara: filkom, aktivasi: binary step (hstep)\n",
            "w1, w2, w3, w4 =\n",
            " [-14.  10.   6.   6.] \n",
            "dan b = -10.0 \n",
            "dalam 10 epoch\n",
            "\n",
            "Cara: wikipedia, aktivasi: binary step (hstep)\n",
            "w1, w2, w3, w4 =\n",
            " [26831791. -5728393.  3230775. -5952169.] \n",
            "dan b = 17872623.0 \n",
            "dalam 10 epoch\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Validasi"
      ],
      "metadata": {
        "id": "qcuym348KO4h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test(data, model, activation, target=None, th=0):\n",
        "  result = []\n",
        "  for i, row in enumerate(data):\n",
        "    net = np.dot(row, model)\n",
        "    f_net = activation(net, th)\n",
        "    result.append(f_net)\n",
        "  if target != None:\n",
        "    print('target:', target)\n",
        "  print('result:', result)\n",
        "\n",
        "print(\"Cara: filkom, aktivasi: bipolar step\")\n",
        "test(dataset, model1, bip_step, target=target)\n",
        "\n",
        "print(\"\\nCara: wikipedia, aktivasi: bipolar step\")\n",
        "test(dataset, model2, bip_step, target=target)\n",
        "\n",
        "print(\"\\nCara: filkom, aktivasi: binary step (hstep)\")\n",
        "test(dataset, model1, bin_step, target=target)\n",
        "\n",
        "print(\"\\nCara: wikipedia, aktivasi: binary step (hstep)\")\n",
        "test(dataset, model2, bin_step, target=target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5zL2n3NGKQGB",
        "outputId": "24fa54fe-b1ba-4715-8b93-e41e12b5e951"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cara: filkom, aktivasi: bipolar step\n",
            "target: [1, 1, -1, -1]\n",
            "result: [1, 1, -1, -1]\n",
            "\n",
            "Cara: wikipedia, aktivasi: bipolar step\n",
            "target: [1, 1, -1, -1]\n",
            "result: [1, -1, 1, 1]\n",
            "\n",
            "Cara: filkom, aktivasi: binary step (hstep)\n",
            "target: [1, 1, -1, -1]\n",
            "result: [1, 1, 0, 0]\n",
            "\n",
            "Cara: wikipedia, aktivasi: binary step (hstep)\n",
            "target: [1, 1, -1, -1]\n",
            "result: [1, 0, 1, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prediksi\n",
        "\n",
        "Data berasal dari studi kasus no. 4"
      ],
      "metadata": {
        "id": "oThktk_HMVxd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = [\n",
        "    [-1,-1,1,1,1],\n",
        "    [-1,-1,-1,-1,1]\n",
        "]\n",
        "\n",
        "print(\"Cara: filkom, aktivasi: bipolar step\")\n",
        "test(data, model1, bip_step)\n",
        "\n",
        "print(\"\\nCara: wikipedia, aktivasi: bipolar step\")\n",
        "test(data, model2, bip_step)\n",
        "\n",
        "print(\"\\nCara: filkom, aktivasi: binary step (hstep)\")\n",
        "test(data, model1, bin_step)\n",
        "\n",
        "print(\"\\nCara: wikipedia, aktivasi: binary step (hstep)\")\n",
        "test(data, model2, bin_step)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w4NbQYEeMXR-",
        "outputId": "6beb5f8e-e33e-4f16-e5c2-bf30b98fe513"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cara: filkom, aktivasi: bipolar step\n",
            "result: [1, -1]\n",
            "\n",
            "Cara: wikipedia, aktivasi: bipolar step\n",
            "result: [-1, -1]\n",
            "\n",
            "Cara: filkom, aktivasi: binary step (hstep)\n",
            "result: [1, 0]\n",
            "\n",
            "Cara: wikipedia, aktivasi: binary step (hstep)\n",
            "result: [0, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Diskusi\n",
        "\n",
        "1. Tampilkan weight terakhir dari hasil pelatihan menggunakan dua weight update\n",
        "\n",
        "|filkom, bipolar|filkom, hstep|wiki, bipolar|wiki, hstep|\n",
        "|---|---|---|---|\n",
        "|`[-2.  2.  0.  2.]`|`[26831791. -5728393.  3230775. -5952169.]`|`[-14.  10.   6.   6.]`|`[26831791. -5728393.  3230775. -5952169.]`|\n",
        "\n",
        "2. Apakah terdapat kekurangan pada rumus weight pertama dan kedua? Jika ada jelaskan\n",
        "\n",
        "Sebenarnya dari kedua rumusan weight tersebut tidak dapat kekurangan; di mana rumusan dari slides FILKOM menggunakan hasil setelah diteruskan melalui fungsi aktivasi, sedangkan pada Wikipedia menggunakan hasil weighted sum sebelum diteruskan ke fungsi aktivasi.\n",
        "\n",
        "3. Jika anda diminta untuk melatih arsitektur perceptron menggunakan 1 juta data dan memprediksi 500 ribu data, rumus weight update mana yang akan anda pilih dan kenapa?\n",
        "\n",
        "Saya akan memilih menggunakan delta rule milik FILKOM karena secara komputasi lebih sederhana.\n",
        "\n",
        "4. Lakukan prediksi dengan data berikut pada masing masing rumus weight update perceptron dan tampilkan hasilnya\n",
        "\n",
        "```\n",
        "Cara: filkom, aktivasi: bipolar step\n",
        "result: [1, -1]\n",
        "\n",
        "Cara: wikipedia, aktivasi: bipolar step\n",
        "result: [-1, -1]\n",
        "\n",
        "Cara: filkom, aktivasi: binary step (hstep)\n",
        "result: [1, 0]\n",
        "\n",
        "Cara: wikipedia, aktivasi: binary step (hstep)\n",
        "result: [0, 0]\n",
        "```"
      ],
      "metadata": {
        "id": "I0kM6Q-QJr-y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Namun demikian, permasalahan utama berada pada pemilihan nilai learning rate. Saat learning rate = 1, delta rule pada slides FILKOM dapat memprediksi hasil-hasil dengan akurasi 100%, sedangkan menggunakan cara pada Wikipedia hanya memiliki akurasi 25%.\n",
        "\n",
        "Untuk menjawab pertanyaan sebelumnya, dalam kasus seperti ini, saya akan masih tetap menggunakan cara berdasarkan slides dari FILKOM karena terlihat memiliki akurasi 100%.\n",
        "\n",
        "Keempat hasil berikut pula menggunakan delta rule dan fungsi aktivasi berdasarkan slides FILKOM dan juga berdasarkan Wikipedia (https://en.wikipedia.org/wiki/Perceptron).\n",
        "\n",
        "Perbedaannya pada learning rate di mana di-set 0.1 atau `1e-1`"
      ],
      "metadata": {
        "id": "q8v8UYd2Ievx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 1e-1\n",
        "\n",
        "model1, epoch = perceptron(dataset, target, w, lr, delta_rule='filkom')\n",
        "print(\"Cara: filkom, aktivasi: bipolar step\")\n",
        "print('w1, w2, w3, w4 =\\n', model1[:-1], '\\ndan b =', model1[-1], '\\ndalam', epoch, 'epoch\\n')\n",
        "\n",
        "model2, epoch = perceptron(dataset, target, w, lr, delta_rule='wiki')\n",
        "print(\"Cara: wikipedia, aktivasi: bipolar step\")\n",
        "print('w1, w2, w3, w4 =\\n', model2[:-1], '\\ndan b =', model2[-1], '\\ndalam', epoch, 'epoch\\n')\n",
        "\n",
        "model3, epoch = perceptron(dataset, target, w, lr, delta_rule='filkom', activation=bin_step)\n",
        "print(\"Cara: filkom, aktivasi: binary step (hstep)\")\n",
        "print('w1, w2, w3, w4 =\\n', model3[:-1], '\\ndan b =', model3[-1], '\\ndalam', epoch, 'epoch\\n')\n",
        "\n",
        "model4, epoch = perceptron(dataset, target, w, lr, delta_rule='wiki', activation=bin_step)\n",
        "print(\"Cara: wikipedia, aktivasi: binary step (hstep)\")\n",
        "print('w1, w2, w3, w4 =\\n', model4[:-1], '\\ndan b =', model4[-1], '\\ndalam', epoch, 'epoch\\n')\n",
        "\n",
        "print(\"Cara: filkom, aktivasi: bipolar step\")\n",
        "test(dataset, model1, bip_step, target=target)\n",
        "\n",
        "print(\"\\nCara: wikipedia, aktivasi: bipolar step\")\n",
        "test(dataset, model2, bip_step, target=target)\n",
        "\n",
        "print(\"\\nCara: filkom, aktivasi: binary step (hstep)\")\n",
        "test(dataset, model1, bin_step, target=target)\n",
        "\n",
        "print(\"\\nCara: wikipedia, aktivasi: binary step (hstep)\")\n",
        "test(dataset, model2, bin_step, target=target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2NAjr_d7HuyQ",
        "outputId": "28ffb86d-d255-469c-87d0-8d6488791deb"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cara: filkom, aktivasi: bipolar step\n",
            "w1, w2, w3, w4 =\n",
            " [-0.2  0.2  0.   0.2] \n",
            "dan b = 0.0 \n",
            "dalam 10 epoch\n",
            "\n",
            "Cara: wikipedia, aktivasi: bipolar step\n",
            "w1, w2, w3, w4 =\n",
            " [-0.84414579  0.80991057 -0.01054852  0.73874642] \n",
            "dan b = -0.02368671098664482 \n",
            "dalam 10 epoch\n",
            "\n",
            "Cara: filkom, aktivasi: binary step (hstep)\n",
            "w1, w2, w3, w4 =\n",
            " [-1.4  1.   0.6  0.6] \n",
            "dan b = -0.9999999999999999 \n",
            "dalam 10 epoch\n",
            "\n",
            "Cara: wikipedia, aktivasi: binary step (hstep)\n",
            "w1, w2, w3, w4 =\n",
            " [-0.84414579  0.80991057 -0.01054852  0.73874642] \n",
            "dan b = -0.02368671098664482 \n",
            "dalam 10 epoch\n",
            "\n",
            "Cara: filkom, aktivasi: bipolar step\n",
            "target: [1, 1, -1, -1]\n",
            "result: [1, 1, -1, -1]\n",
            "\n",
            "Cara: wikipedia, aktivasi: bipolar step\n",
            "target: [1, 1, -1, -1]\n",
            "result: [1, 1, -1, -1]\n",
            "\n",
            "Cara: filkom, aktivasi: binary step (hstep)\n",
            "target: [1, 1, -1, -1]\n",
            "result: [1, 1, 0, 0]\n",
            "\n",
            "Cara: wikipedia, aktivasi: binary step (hstep)\n",
            "target: [1, 1, -1, -1]\n",
            "result: [1, 1, 0, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Terlihat dari hasil validasi:\n",
        "\n",
        "```\n",
        "Cara: filkom, aktivasi: bipolar step\n",
        "target: [1, 1, -1, -1]\n",
        "result: [1, 1, -1, -1]\n",
        "\n",
        "Cara: wikipedia, aktivasi: bipolar step\n",
        "target: [1, 1, -1, -1]\n",
        "result: [1, 1, -1, -1]\n",
        "\n",
        "Cara: filkom, aktivasi: binary step (hstep)\n",
        "target: [1, 1, -1, -1]\n",
        "result: [1, 1, 0, 0]\n",
        "\n",
        "Cara: wikipedia, aktivasi: binary step (hstep)\n",
        "target: [1, 1, -1, -1]\n",
        "result: [1, 1, 0, 0]\n",
        "```\n",
        "\n",
        "di mana kedua delta rule menghasilkan akurasi 100%."
      ],
      "metadata": {
        "id": "uXqyS_VsNU-F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = [\n",
        "    [-1,-1,1,1,1],\n",
        "    [-1,-1,-1,-1,1]\n",
        "]\n",
        "\n",
        "print(\"Cara: filkom, aktivasi: bipolar step\")\n",
        "test(data, model1, bip_step)\n",
        "\n",
        "print(\"\\nCara: wikipedia, aktivasi: bipolar step\")\n",
        "test(data, model2, bip_step)\n",
        "\n",
        "print(\"\\nCara: filkom, aktivasi: binary step (hstep)\")\n",
        "test(data, model1, bin_step)\n",
        "\n",
        "print(\"\\nCara: wikipedia, aktivasi: binary step (hstep)\")\n",
        "test(data, model2, bin_step)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bAeRcCKNOBFT",
        "outputId": "5b1d2380-bb65-4838-9932-b87a816a5eaa"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cara: filkom, aktivasi: bipolar step\n",
            "result: [1, -1]\n",
            "\n",
            "Cara: wikipedia, aktivasi: bipolar step\n",
            "result: [1, -1]\n",
            "\n",
            "Cara: filkom, aktivasi: binary step (hstep)\n",
            "result: [1, 0]\n",
            "\n",
            "Cara: wikipedia, aktivasi: binary step (hstep)\n",
            "result: [1, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Terlihat sekarang hasil prediksi saat nilai learning rate = 0.1 sama antara perceptron yang menggunakan delta rule pada slides FILKOM maupun Wikipedia."
      ],
      "metadata": {
        "id": "GMjWED-HOHRf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Kesimpulan\n",
        "\n",
        "Tidak ada permasalahan pada delta rule antara slides FILKOM dan Wikipedia. Nilai learning rate memainkan peran penting dalam kovergensi perceptron dan akurasi saat prediksi."
      ],
      "metadata": {
        "id": "M9cQKRMUOAhE"
      }
    }
  ]
}