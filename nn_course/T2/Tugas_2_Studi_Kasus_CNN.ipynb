{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPDiCT8Jmr8mkOXpserbK2i",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hugoalfedoputra-ub/ml/blob/main/nn_course/T2/Tugas_2_Studi_Kasus_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Studi Kasus CNN\n",
        "Deep Learning B\n",
        "\n",
        "Hugo Alfedo Putra\\\n",
        "225150201111013\n",
        "\n",
        "04 Oktober 2024"
      ],
      "metadata": {
        "id": "16ikW5dTgi3I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Colab ini berdasarkan tutorial dari PyTorch: https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html dan milik yunjey: https://github.com/yunjey/pytorch-tutorial/blob/master/tutorials/01-basics/feedforward_neural_network/main.py."
      ],
      "metadata": {
        "id": "A4DokzMUgrOP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xXHJ8nu8W12l"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deklarasi parameter untuk model yang akan dilatih dengan dataset MNIST dan CIFAR-10 dibuat mirip terlebih dahulu berdasarkan tutorial dari PyTorch. Perbedaan pada parameter model MNIST adalah besar kernel convolution, di mana pada CIFAR-10 digunakan 5 sedangkan pada MNIST digunakan 4 karena dimensi data MNIST yang lebih kecil daripada data CIFAR-10."
      ],
      "metadata": {
        "id": "I7PMzu-cosxG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameter untuk MNIST\n",
        "mnist_input_size = 28\n",
        "mnist_hidden_size = [120, 84]\n",
        "mnist_num_classes = 10\n",
        "mnist_num_epochs = 5\n",
        "mnist_batch_size = 100\n",
        "mnist_learning_rate = 0.001\n",
        "mnist_in_channels = 1 # karena kedalamannya 1 (grayscale)\n",
        "mnist_conv1_out_channels = 6\n",
        "mnist_conv2_out_channels = 16\n",
        "mnist_conv_kernel_size = 4\n",
        "mnist_pool_kernel_size = 2\n",
        "mnist_stride = 2"
      ],
      "metadata": {
        "id": "dSjDpYxhc6lj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameter untuk CIFAR\n",
        "cifar_input_size = 32\n",
        "cifar_hidden_size = [120, 84]\n",
        "cifar_num_classes = 10\n",
        "cifar_num_epochs = 3\n",
        "cifar_batch_size = 4\n",
        "cifar_learning_rate = 0.001\n",
        "cifar_in_channels = 3 # karena kedalamannya 3 (RGB)\n",
        "cifar_conv1_out_channels = 6\n",
        "cifar_conv2_out_channels = 16\n",
        "cifar_conv_kernel_size = 5\n",
        "cifar_pool_kernel_size = 2\n",
        "cifar_stride = 2"
      ],
      "metadata": {
        "id": "DNdO7Z0wc1Q7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download dataset"
      ],
      "metadata": {
        "id": "XhB2miUYhE35"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# MNIST dataset\n",
        "transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0,), (1,))\n",
        "])\n",
        "\n",
        "mnist_train_set = torchvision.datasets.MNIST(root='../../data',\n",
        "                                           train=True,\n",
        "                                           transform=transforms.ToTensor(),\n",
        "                                           download=True)\n",
        "\n",
        "mnist_test_set = torchvision.datasets.MNIST(root='../../data',\n",
        "                                          train=False,\n",
        "                                          transform=transforms.ToTensor())\n",
        "\n",
        "# Data loader\n",
        "mnist_train_loader = torch.utils.data.DataLoader(dataset=mnist_train_set,\n",
        "                                           batch_size=mnist_batch_size,\n",
        "                                           shuffle=True)\n",
        "\n",
        "mnist_test_loader = torch.utils.data.DataLoader(dataset=mnist_test_set,\n",
        "                                          batch_size=mnist_batch_size,\n",
        "                                          shuffle=False)"
      ],
      "metadata": {
        "id": "9SFMXvaHXEfJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CIFAR-10 dataset\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "cifar_train_set = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "cifar_test_set = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "\n",
        "# Data loader\n",
        "cifar_train_loader = torch.utils.data.DataLoader(cifar_train_set, batch_size=cifar_batch_size,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "cifar_test_loader = torch.utils.data.DataLoader(cifar_test_set, batch_size=cifar_batch_size,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vRffA8MVXZCs",
        "outputId": "e0197906-eceb-4825-abc5-9df4243dfe29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Definisi kelas Net\n",
        "\n",
        "Dilakukan modifikasi dari tutorial PyTorch agar dapat dimodifikasi sesuai dengan parameter-parameter khusus untuk dataset tertentu. Terlihat pula pada deklarasi self.net bahwa arsitektur NN sbb.:\n",
        "\n",
        "1. Layer input\n",
        "2. Layer convolutional pertama yang diaktivasi dengan ReLU\n",
        "3. Layer pooling pertama\n",
        "4. Layer convolutional kedua yang diaktivasi dengan ReLU\n",
        "5. Layer pooling kedua\n",
        "6. Layer FC (dense) pertama hasil flattening dari pooling kedua yang diaktivasi dengan ReLU\n",
        "7. Layer FC kedua yang diaktivasi dengan ReLU\n",
        "8. Layer FC ketiga sebagai output dengan 10 kelas (tanpa aktivasi untuk training karena output akan diteruskan ke loss, optimasi, dan backpropagation)"
      ],
      "metadata": {
        "id": "cVxynHzbhHuA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(nn.Module):\n",
        "  def __init__(\n",
        "      self,\n",
        "      input_size,\n",
        "      hidden_size,\n",
        "      in_channels,\n",
        "      conv1_out_channels,\n",
        "      conv2_out_channels,\n",
        "      conv_kernel_size,\n",
        "      pool_kernel_size,\n",
        "      num_classes,\n",
        "      stride=2\n",
        "      ):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels, conv1_out_channels, conv_kernel_size)\n",
        "    self.pool = nn.MaxPool2d(pool_kernel_size, stride)\n",
        "    self.conv2 = nn.Conv2d(conv1_out_channels, conv2_out_channels, conv_kernel_size)\n",
        "    self.fc1 = nn.Linear(\n",
        "        self._get_flattened_size(input_size, conv1_out_channels, conv2_out_channels, conv_kernel_size, pool_kernel_size, stride),\n",
        "        hidden_size[0])\n",
        "    self.fc2 = nn.Linear(hidden_size[0], hidden_size[1])\n",
        "    self.fc3 = nn.Linear(hidden_size[1], num_classes)\n",
        "    self.net = nn.Sequential(\n",
        "        self.conv1, nn.ReLU(),\n",
        "        self.pool,\n",
        "        self.conv2, nn.ReLU(),\n",
        "        self.pool,\n",
        "        nn.Flatten(),\n",
        "        self.fc1, nn.ReLU(),\n",
        "        self.fc2, nn.ReLU(),\n",
        "        self.fc3\n",
        "    )\n",
        "\n",
        "  def _get_flattened_size(self, input_size, conv1_out, conv2_out, kernel_size, pool_size, stride):\n",
        "    conv1_out_size = (input_size - kernel_size) + 1\n",
        "    pool1_out_size = (conv1_out_size - pool_size) // stride + 1\n",
        "    conv2_out_size = (pool1_out_size - kernel_size) + 1\n",
        "    pool2_out_size = (conv2_out_size - pool_size) // stride + 1\n",
        "    return conv2_out * pool2_out_size * pool2_out_size\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.pool(F.relu(self.conv1(x)))\n",
        "    x = self.pool(F.relu(self.conv2(x)))\n",
        "    x = torch.flatten(x, 1)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.fc3(x)\n",
        "    return x\n",
        "\n",
        "  # Berdasarkan https://www.d2l.ai/chapter_convolutional-neural-networks/lenet.html\n",
        "  # untuk merincikan layer apa saja pada net dan shape-nya\n",
        "  def layer_summary(self, input_shape):\n",
        "    X = torch.randn(*input_shape)\n",
        "    for layer in self.net:\n",
        "      X = layer(X)\n",
        "      print(layer.__class__.__name__, 'output shape:\\t', X.shape)"
      ],
      "metadata": {
        "id": "Etodz02HYnpk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deklarasi model untuk dataset MNIST"
      ],
      "metadata": {
        "id": "-6zywpNThNqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mnist_model = Net(\n",
        "    mnist_input_size,\n",
        "    mnist_hidden_size,\n",
        "    mnist_in_channels,\n",
        "    mnist_conv1_out_channels,\n",
        "    mnist_conv2_out_channels,\n",
        "    mnist_conv_kernel_size,\n",
        "    mnist_pool_kernel_size,\n",
        "    mnist_num_classes,\n",
        "    mnist_stride).to(device)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(mnist_model.parameters(), lr=mnist_learning_rate)"
      ],
      "metadata": {
        "id": "sXuvvFK3YvUj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deklarasi model untuk dataset CIFAR-10"
      ],
      "metadata": {
        "id": "Ir_UrysxhPty"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cifar_model = Net(\n",
        "    cifar_input_size,\n",
        "    cifar_hidden_size,\n",
        "    cifar_in_channels,\n",
        "    cifar_conv1_out_channels,\n",
        "    cifar_conv2_out_channels,\n",
        "    cifar_conv_kernel_size,\n",
        "    cifar_pool_kernel_size,\n",
        "    cifar_num_classes,\n",
        "    cifar_stride).to(device)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(cifar_model.parameters(), lr=cifar_learning_rate, momentum=0.9)"
      ],
      "metadata": {
        "id": "3MCvPESGdtRW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Definisi fungsi train dan test model"
      ],
      "metadata": {
        "id": "RyFy7MSxhSzx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_test_model(model, train_loader, num_epochs, input_size, test_loader):\n",
        "  # Train the model\n",
        "  total_step = len(train_loader)\n",
        "  losses = []\n",
        "  for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "      # Move tensors to the configured device\n",
        "      images = images.to(device)\n",
        "      labels = labels.to(device)\n",
        "\n",
        "      # Forward pass\n",
        "      outputs = model(images)\n",
        "      loss = criterion(outputs, labels)\n",
        "\n",
        "      # Backward and optimize\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      losses.append(loss.item())\n",
        "\n",
        "      if (i+1) % 100 == 0:\n",
        "        print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
        "                .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
        "\n",
        "  # Test the model\n",
        "  # In test phase, we don't need to compute gradients (for memory efficiency)\n",
        "  with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "      images = images.to(device)\n",
        "      labels = labels.to(device)\n",
        "      outputs = model(images)\n",
        "      _, predicted = torch.max(outputs.data, 1)\n",
        "      total += labels.size(0)\n",
        "      correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print('Accuracy of the network on the 10000 test images: {} %'.format(100 * correct / total))"
      ],
      "metadata": {
        "id": "oPFeIPNrYvxj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hasil"
      ],
      "metadata": {
        "id": "_uK01ZobhVWU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Informasi arsitektur net MNIST"
      ],
      "metadata": {
        "id": "z3-R3B07hW3O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mnist_model.layer_summary((mnist_batch_size, mnist_in_channels, mnist_input_size, mnist_input_size))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TCWh6SFyCS5O",
        "outputId": "cf309b99-8adf-4ad5-e93e-d17bf9d56fc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conv2d output shape:\t torch.Size([100, 6, 25, 25])\n",
            "ReLU output shape:\t torch.Size([100, 6, 25, 25])\n",
            "MaxPool2d output shape:\t torch.Size([100, 6, 12, 12])\n",
            "Conv2d output shape:\t torch.Size([100, 16, 9, 9])\n",
            "ReLU output shape:\t torch.Size([100, 16, 9, 9])\n",
            "MaxPool2d output shape:\t torch.Size([100, 16, 4, 4])\n",
            "Flatten output shape:\t torch.Size([100, 256])\n",
            "Linear output shape:\t torch.Size([100, 120])\n",
            "ReLU output shape:\t torch.Size([100, 120])\n",
            "Linear output shape:\t torch.Size([100, 84])\n",
            "ReLU output shape:\t torch.Size([100, 84])\n",
            "Linear output shape:\t torch.Size([100, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Formatnya apabila terdapat empat parameter berupa:\\\n",
        "`[batch size, banyak channel, tinggi, lebar]`\n",
        "\n",
        "Pada dua parameter menunjukkan batch size dan banyaknya neuron saja."
      ],
      "metadata": {
        "id": "1LL5N4Snjc2M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hasil train dan test model MNIST"
      ],
      "metadata": {
        "id": "77mGPDLXhe87"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_and_test_model(mnist_model, mnist_train_loader, mnist_num_epochs, mnist_input_size, mnist_test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ekLqNbPEeGRK",
        "outputId": "545e3b28-001c-49cb-9b73-d879bc7170b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Step [100/600], Loss: 2.3087\n",
            "Epoch [1/5], Step [200/600], Loss: 2.3003\n",
            "Epoch [1/5], Step [300/600], Loss: 2.3053\n",
            "Epoch [1/5], Step [400/600], Loss: 2.3077\n",
            "Epoch [1/5], Step [500/600], Loss: 2.2956\n",
            "Epoch [1/5], Step [600/600], Loss: 2.3121\n",
            "Epoch [2/5], Step [100/600], Loss: 2.3264\n",
            "Epoch [2/5], Step [200/600], Loss: 2.3056\n",
            "Epoch [2/5], Step [300/600], Loss: 2.3125\n",
            "Epoch [2/5], Step [400/600], Loss: 2.3025\n",
            "Epoch [2/5], Step [500/600], Loss: 2.2955\n",
            "Epoch [2/5], Step [600/600], Loss: 2.3079\n",
            "Epoch [3/5], Step [100/600], Loss: 2.2898\n",
            "Epoch [3/5], Step [200/600], Loss: 2.3178\n",
            "Epoch [3/5], Step [300/600], Loss: 2.3082\n",
            "Epoch [3/5], Step [400/600], Loss: 2.3005\n",
            "Epoch [3/5], Step [500/600], Loss: 2.3071\n",
            "Epoch [3/5], Step [600/600], Loss: 2.3148\n",
            "Epoch [4/5], Step [100/600], Loss: 2.2954\n",
            "Epoch [4/5], Step [200/600], Loss: 2.3064\n",
            "Epoch [4/5], Step [300/600], Loss: 2.2986\n",
            "Epoch [4/5], Step [400/600], Loss: 2.3127\n",
            "Epoch [4/5], Step [500/600], Loss: 2.2955\n",
            "Epoch [4/5], Step [600/600], Loss: 2.3047\n",
            "Epoch [5/5], Step [100/600], Loss: 2.3112\n",
            "Epoch [5/5], Step [200/600], Loss: 2.3003\n",
            "Epoch [5/5], Step [300/600], Loss: 2.3204\n",
            "Epoch [5/5], Step [400/600], Loss: 2.3057\n",
            "Epoch [5/5], Step [500/600], Loss: 2.3053\n",
            "Epoch [5/5], Step [600/600], Loss: 2.3053\n",
            "Accuracy of the network on the 10000 test images: 16.13 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hasil menunjukkan akurasi 16.13%: tidak cukup lebih baik dibandingan menjawab secara acak (akurasi ~10% menganggap probabilitas uniform). Hal ini dapat disebabkan oleh hidden layer dengan neuron yang terlalu sedikit (untuk contoh, disamakan dengan inisialisasi CIFAR-10, yaitu 120 padahal tutorial yunjey menggunakan 500) dan ukuran kernel size yang terlalu besar untuk ukuran data 28x28. Maka dilakukan perubahan pada model dan pelatihan ulang sehingga mendapatkan hasil sbb.:"
      ],
      "metadata": {
        "id": "xbgJgQHIkAom"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mnist_model = Net(\n",
        "    mnist_input_size,\n",
        "    [600, 500],\n",
        "    mnist_in_channels,\n",
        "    mnist_conv1_out_channels,\n",
        "    mnist_conv2_out_channels,\n",
        "    3,\n",
        "    mnist_pool_kernel_size,\n",
        "    mnist_num_classes,\n",
        "    mnist_stride).to(device)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(mnist_model.parameters(), lr=mnist_learning_rate)"
      ],
      "metadata": {
        "id": "w5AenDWBkpgV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mnist_model.layer_summary((mnist_batch_size, mnist_in_channels, mnist_input_size, mnist_input_size))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mm0_oquollwu",
        "outputId": "40a2d01a-fc47-47c1-a852-0afe9da79696"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conv2d output shape:\t torch.Size([100, 6, 26, 26])\n",
            "ReLU output shape:\t torch.Size([100, 6, 26, 26])\n",
            "MaxPool2d output shape:\t torch.Size([100, 6, 13, 13])\n",
            "Conv2d output shape:\t torch.Size([100, 16, 11, 11])\n",
            "ReLU output shape:\t torch.Size([100, 16, 11, 11])\n",
            "MaxPool2d output shape:\t torch.Size([100, 16, 5, 5])\n",
            "Flatten output shape:\t torch.Size([100, 400])\n",
            "Linear output shape:\t torch.Size([100, 600])\n",
            "ReLU output shape:\t torch.Size([100, 600])\n",
            "Linear output shape:\t torch.Size([100, 500])\n",
            "ReLU output shape:\t torch.Size([100, 500])\n",
            "Linear output shape:\t torch.Size([100, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_and_test_model(mnist_model, mnist_train_loader, mnist_num_epochs, mnist_input_size, mnist_test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pb87qlYglmHU",
        "outputId": "44fd596c-141c-455d-927c-a1a0d2a682a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Step [100/600], Loss: 0.2715\n",
            "Epoch [1/5], Step [200/600], Loss: 0.1280\n",
            "Epoch [1/5], Step [300/600], Loss: 0.2722\n",
            "Epoch [1/5], Step [400/600], Loss: 0.1339\n",
            "Epoch [1/5], Step [500/600], Loss: 0.2270\n",
            "Epoch [1/5], Step [600/600], Loss: 0.1560\n",
            "Epoch [2/5], Step [100/600], Loss: 0.0332\n",
            "Epoch [2/5], Step [200/600], Loss: 0.1687\n",
            "Epoch [2/5], Step [300/600], Loss: 0.0489\n",
            "Epoch [2/5], Step [400/600], Loss: 0.0673\n",
            "Epoch [2/5], Step [500/600], Loss: 0.0286\n",
            "Epoch [2/5], Step [600/600], Loss: 0.0202\n",
            "Epoch [3/5], Step [100/600], Loss: 0.0269\n",
            "Epoch [3/5], Step [200/600], Loss: 0.0673\n",
            "Epoch [3/5], Step [300/600], Loss: 0.0242\n",
            "Epoch [3/5], Step [400/600], Loss: 0.1110\n",
            "Epoch [3/5], Step [500/600], Loss: 0.2090\n",
            "Epoch [3/5], Step [600/600], Loss: 0.0101\n",
            "Epoch [4/5], Step [100/600], Loss: 0.0072\n",
            "Epoch [4/5], Step [200/600], Loss: 0.0243\n",
            "Epoch [4/5], Step [300/600], Loss: 0.0221\n",
            "Epoch [4/5], Step [400/600], Loss: 0.0307\n",
            "Epoch [4/5], Step [500/600], Loss: 0.0806\n",
            "Epoch [4/5], Step [600/600], Loss: 0.0255\n",
            "Epoch [5/5], Step [100/600], Loss: 0.0049\n",
            "Epoch [5/5], Step [200/600], Loss: 0.0462\n",
            "Epoch [5/5], Step [300/600], Loss: 0.0259\n",
            "Epoch [5/5], Step [400/600], Loss: 0.1195\n",
            "Epoch [5/5], Step [500/600], Loss: 0.0100\n",
            "Epoch [5/5], Step [600/600], Loss: 0.0042\n",
            "Accuracy of the network on the 10000 test images: 98.89 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Akurasi setelah menggunakan banyak neuron yang mirip dengan contoh yunjey adalah 98.89%, bahkan lebih baik daripada model milik yunjey. Dari sini dapat diimplikasikan bahwa convolution efektif dalam membantu klasifikasi dengan dense network; pada Tugas 1 ditunjukkan bahwa penambahan hidden layer saja relatif mempunyai dampak buruk pada akurasi model."
      ],
      "metadata": {
        "id": "z6ZUTCdUpDar"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Informasi arsitektur net CIFAR-10"
      ],
      "metadata": {
        "id": "irYYpWAEhcRa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cifar_model.layer_summary((cifar_batch_size, cifar_in_channels, cifar_input_size, cifar_input_size))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nsc3-FU6CXOh",
        "outputId": "f2d859fb-b25a-4a5e-8e92-ae7c39949d03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conv2d output shape:\t torch.Size([4, 6, 28, 28])\n",
            "ReLU output shape:\t torch.Size([4, 6, 28, 28])\n",
            "MaxPool2d output shape:\t torch.Size([4, 6, 14, 14])\n",
            "Conv2d output shape:\t torch.Size([4, 16, 10, 10])\n",
            "ReLU output shape:\t torch.Size([4, 16, 10, 10])\n",
            "MaxPool2d output shape:\t torch.Size([4, 16, 5, 5])\n",
            "Flatten output shape:\t torch.Size([4, 400])\n",
            "Linear output shape:\t torch.Size([4, 120])\n",
            "ReLU output shape:\t torch.Size([4, 120])\n",
            "Linear output shape:\t torch.Size([4, 84])\n",
            "ReLU output shape:\t torch.Size([4, 84])\n",
            "Linear output shape:\t torch.Size([4, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Formatnya apabila terdapat empat parameter berupa:\\\n",
        "`[batch size, banyak channel, tinggi, lebar]`\n",
        "\n",
        "Pada dua parameter menunjukkan batch size dan banyaknya neuron saja."
      ],
      "metadata": {
        "id": "CUaLhuKljgsV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hasil train dan test model CIFAR-10"
      ],
      "metadata": {
        "id": "jcHVVHShhiAC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_and_test_model(cifar_model, cifar_train_loader, cifar_num_epochs, cifar_input_size, cifar_test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mv02E7V3ePp2",
        "outputId": "601f53dd-9f4f-447e-f847-c1606e22d686"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/3], Step [100/12500], Loss: 2.3240\n",
            "Epoch [1/3], Step [200/12500], Loss: 2.3064\n",
            "Epoch [1/3], Step [300/12500], Loss: 2.2545\n",
            "Epoch [1/3], Step [400/12500], Loss: 2.3129\n",
            "Epoch [1/3], Step [500/12500], Loss: 2.3256\n",
            "Epoch [1/3], Step [600/12500], Loss: 2.3452\n",
            "Epoch [1/3], Step [700/12500], Loss: 2.3155\n",
            "Epoch [1/3], Step [800/12500], Loss: 2.3149\n",
            "Epoch [1/3], Step [900/12500], Loss: 2.2596\n",
            "Epoch [1/3], Step [1000/12500], Loss: 2.3020\n",
            "Epoch [1/3], Step [1100/12500], Loss: 2.1961\n",
            "Epoch [1/3], Step [1200/12500], Loss: 2.1139\n",
            "Epoch [1/3], Step [1300/12500], Loss: 2.2170\n",
            "Epoch [1/3], Step [1400/12500], Loss: 2.1694\n",
            "Epoch [1/3], Step [1500/12500], Loss: 1.9377\n",
            "Epoch [1/3], Step [1600/12500], Loss: 1.8786\n",
            "Epoch [1/3], Step [1700/12500], Loss: 1.7861\n",
            "Epoch [1/3], Step [1800/12500], Loss: 1.9958\n",
            "Epoch [1/3], Step [1900/12500], Loss: 1.6890\n",
            "Epoch [1/3], Step [2000/12500], Loss: 2.3929\n",
            "Epoch [1/3], Step [2100/12500], Loss: 1.7779\n",
            "Epoch [1/3], Step [2200/12500], Loss: 2.7478\n",
            "Epoch [1/3], Step [2300/12500], Loss: 1.6480\n",
            "Epoch [1/3], Step [2400/12500], Loss: 1.9887\n",
            "Epoch [1/3], Step [2500/12500], Loss: 1.9975\n",
            "Epoch [1/3], Step [2600/12500], Loss: 1.5374\n",
            "Epoch [1/3], Step [2700/12500], Loss: 1.7674\n",
            "Epoch [1/3], Step [2800/12500], Loss: 1.8893\n",
            "Epoch [1/3], Step [2900/12500], Loss: 1.5466\n",
            "Epoch [1/3], Step [3000/12500], Loss: 2.4532\n",
            "Epoch [1/3], Step [3100/12500], Loss: 1.8769\n",
            "Epoch [1/3], Step [3200/12500], Loss: 2.2642\n",
            "Epoch [1/3], Step [3300/12500], Loss: 1.5699\n",
            "Epoch [1/3], Step [3400/12500], Loss: 2.1978\n",
            "Epoch [1/3], Step [3500/12500], Loss: 2.0931\n",
            "Epoch [1/3], Step [3600/12500], Loss: 1.4353\n",
            "Epoch [1/3], Step [3700/12500], Loss: 1.6117\n",
            "Epoch [1/3], Step [3800/12500], Loss: 1.9358\n",
            "Epoch [1/3], Step [3900/12500], Loss: 2.7117\n",
            "Epoch [1/3], Step [4000/12500], Loss: 2.2142\n",
            "Epoch [1/3], Step [4100/12500], Loss: 1.4565\n",
            "Epoch [1/3], Step [4200/12500], Loss: 1.6249\n",
            "Epoch [1/3], Step [4300/12500], Loss: 2.3013\n",
            "Epoch [1/3], Step [4400/12500], Loss: 1.2157\n",
            "Epoch [1/3], Step [4500/12500], Loss: 1.7456\n",
            "Epoch [1/3], Step [4600/12500], Loss: 0.8168\n",
            "Epoch [1/3], Step [4700/12500], Loss: 1.6460\n",
            "Epoch [1/3], Step [4800/12500], Loss: 1.1772\n",
            "Epoch [1/3], Step [4900/12500], Loss: 1.5511\n",
            "Epoch [1/3], Step [5000/12500], Loss: 1.1644\n",
            "Epoch [1/3], Step [5100/12500], Loss: 1.2754\n",
            "Epoch [1/3], Step [5200/12500], Loss: 1.7271\n",
            "Epoch [1/3], Step [5300/12500], Loss: 2.0818\n",
            "Epoch [1/3], Step [5400/12500], Loss: 1.0821\n",
            "Epoch [1/3], Step [5500/12500], Loss: 0.9871\n",
            "Epoch [1/3], Step [5600/12500], Loss: 1.7827\n",
            "Epoch [1/3], Step [5700/12500], Loss: 1.6715\n",
            "Epoch [1/3], Step [5800/12500], Loss: 1.7922\n",
            "Epoch [1/3], Step [5900/12500], Loss: 1.1532\n",
            "Epoch [1/3], Step [6000/12500], Loss: 1.7083\n",
            "Epoch [1/3], Step [6100/12500], Loss: 1.5316\n",
            "Epoch [1/3], Step [6200/12500], Loss: 2.0413\n",
            "Epoch [1/3], Step [6300/12500], Loss: 1.3356\n",
            "Epoch [1/3], Step [6400/12500], Loss: 2.2515\n",
            "Epoch [1/3], Step [6500/12500], Loss: 2.3768\n",
            "Epoch [1/3], Step [6600/12500], Loss: 1.6974\n",
            "Epoch [1/3], Step [6700/12500], Loss: 1.6264\n",
            "Epoch [1/3], Step [6800/12500], Loss: 1.1144\n",
            "Epoch [1/3], Step [6900/12500], Loss: 1.4542\n",
            "Epoch [1/3], Step [7000/12500], Loss: 2.1628\n",
            "Epoch [1/3], Step [7100/12500], Loss: 1.2193\n",
            "Epoch [1/3], Step [7200/12500], Loss: 1.4941\n",
            "Epoch [1/3], Step [7300/12500], Loss: 0.4834\n",
            "Epoch [1/3], Step [7400/12500], Loss: 1.2504\n",
            "Epoch [1/3], Step [7500/12500], Loss: 1.5422\n",
            "Epoch [1/3], Step [7600/12500], Loss: 1.2173\n",
            "Epoch [1/3], Step [7700/12500], Loss: 1.7612\n",
            "Epoch [1/3], Step [7800/12500], Loss: 1.3404\n",
            "Epoch [1/3], Step [7900/12500], Loss: 0.6822\n",
            "Epoch [1/3], Step [8000/12500], Loss: 1.4645\n",
            "Epoch [1/3], Step [8100/12500], Loss: 2.6099\n",
            "Epoch [1/3], Step [8200/12500], Loss: 0.6468\n",
            "Epoch [1/3], Step [8300/12500], Loss: 2.2349\n",
            "Epoch [1/3], Step [8400/12500], Loss: 1.2734\n",
            "Epoch [1/3], Step [8500/12500], Loss: 1.0424\n",
            "Epoch [1/3], Step [8600/12500], Loss: 1.3440\n",
            "Epoch [1/3], Step [8700/12500], Loss: 1.7755\n",
            "Epoch [1/3], Step [8800/12500], Loss: 1.0983\n",
            "Epoch [1/3], Step [8900/12500], Loss: 1.1718\n",
            "Epoch [1/3], Step [9000/12500], Loss: 2.1348\n",
            "Epoch [1/3], Step [9100/12500], Loss: 1.0359\n",
            "Epoch [1/3], Step [9200/12500], Loss: 1.6700\n",
            "Epoch [1/3], Step [9300/12500], Loss: 1.0876\n",
            "Epoch [1/3], Step [9400/12500], Loss: 2.0114\n",
            "Epoch [1/3], Step [9500/12500], Loss: 2.0593\n",
            "Epoch [1/3], Step [9600/12500], Loss: 2.1640\n",
            "Epoch [1/3], Step [9700/12500], Loss: 1.6147\n",
            "Epoch [1/3], Step [9800/12500], Loss: 1.1944\n",
            "Epoch [1/3], Step [9900/12500], Loss: 1.6396\n",
            "Epoch [1/3], Step [10000/12500], Loss: 2.0783\n",
            "Epoch [1/3], Step [10100/12500], Loss: 1.0956\n",
            "Epoch [1/3], Step [10200/12500], Loss: 0.9746\n",
            "Epoch [1/3], Step [10300/12500], Loss: 1.2266\n",
            "Epoch [1/3], Step [10400/12500], Loss: 0.8291\n",
            "Epoch [1/3], Step [10500/12500], Loss: 1.2244\n",
            "Epoch [1/3], Step [10600/12500], Loss: 1.0593\n",
            "Epoch [1/3], Step [10700/12500], Loss: 1.0113\n",
            "Epoch [1/3], Step [10800/12500], Loss: 1.7718\n",
            "Epoch [1/3], Step [10900/12500], Loss: 1.7511\n",
            "Epoch [1/3], Step [11000/12500], Loss: 1.4251\n",
            "Epoch [1/3], Step [11100/12500], Loss: 1.0947\n",
            "Epoch [1/3], Step [11200/12500], Loss: 1.7325\n",
            "Epoch [1/3], Step [11300/12500], Loss: 0.9173\n",
            "Epoch [1/3], Step [11400/12500], Loss: 1.8905\n",
            "Epoch [1/3], Step [11500/12500], Loss: 1.4907\n",
            "Epoch [1/3], Step [11600/12500], Loss: 0.9863\n",
            "Epoch [1/3], Step [11700/12500], Loss: 2.3480\n",
            "Epoch [1/3], Step [11800/12500], Loss: 0.7857\n",
            "Epoch [1/3], Step [11900/12500], Loss: 1.3701\n",
            "Epoch [1/3], Step [12000/12500], Loss: 0.9122\n",
            "Epoch [1/3], Step [12100/12500], Loss: 0.8710\n",
            "Epoch [1/3], Step [12200/12500], Loss: 0.9241\n",
            "Epoch [1/3], Step [12300/12500], Loss: 2.0552\n",
            "Epoch [1/3], Step [12400/12500], Loss: 1.6832\n",
            "Epoch [1/3], Step [12500/12500], Loss: 1.3934\n",
            "Epoch [2/3], Step [100/12500], Loss: 1.7078\n",
            "Epoch [2/3], Step [200/12500], Loss: 1.7166\n",
            "Epoch [2/3], Step [300/12500], Loss: 0.8841\n",
            "Epoch [2/3], Step [400/12500], Loss: 1.0584\n",
            "Epoch [2/3], Step [500/12500], Loss: 0.8724\n",
            "Epoch [2/3], Step [600/12500], Loss: 1.8682\n",
            "Epoch [2/3], Step [700/12500], Loss: 1.4988\n",
            "Epoch [2/3], Step [800/12500], Loss: 1.5655\n",
            "Epoch [2/3], Step [900/12500], Loss: 0.3397\n",
            "Epoch [2/3], Step [1000/12500], Loss: 1.4947\n",
            "Epoch [2/3], Step [1100/12500], Loss: 1.5261\n",
            "Epoch [2/3], Step [1200/12500], Loss: 1.7994\n",
            "Epoch [2/3], Step [1300/12500], Loss: 0.9463\n",
            "Epoch [2/3], Step [1400/12500], Loss: 1.6530\n",
            "Epoch [2/3], Step [1500/12500], Loss: 1.1285\n",
            "Epoch [2/3], Step [1600/12500], Loss: 1.7072\n",
            "Epoch [2/3], Step [1700/12500], Loss: 0.8582\n",
            "Epoch [2/3], Step [1800/12500], Loss: 0.9800\n",
            "Epoch [2/3], Step [1900/12500], Loss: 1.0791\n",
            "Epoch [2/3], Step [2000/12500], Loss: 1.2156\n",
            "Epoch [2/3], Step [2100/12500], Loss: 2.5992\n",
            "Epoch [2/3], Step [2200/12500], Loss: 1.5791\n",
            "Epoch [2/3], Step [2300/12500], Loss: 0.5890\n",
            "Epoch [2/3], Step [2400/12500], Loss: 2.3021\n",
            "Epoch [2/3], Step [2500/12500], Loss: 1.2722\n",
            "Epoch [2/3], Step [2600/12500], Loss: 1.1728\n",
            "Epoch [2/3], Step [2700/12500], Loss: 1.6199\n",
            "Epoch [2/3], Step [2800/12500], Loss: 1.8312\n",
            "Epoch [2/3], Step [2900/12500], Loss: 0.6698\n",
            "Epoch [2/3], Step [3000/12500], Loss: 1.4152\n",
            "Epoch [2/3], Step [3100/12500], Loss: 0.8306\n",
            "Epoch [2/3], Step [3200/12500], Loss: 1.4336\n",
            "Epoch [2/3], Step [3300/12500], Loss: 1.1954\n",
            "Epoch [2/3], Step [3400/12500], Loss: 1.4295\n",
            "Epoch [2/3], Step [3500/12500], Loss: 1.7518\n",
            "Epoch [2/3], Step [3600/12500], Loss: 1.5728\n",
            "Epoch [2/3], Step [3700/12500], Loss: 0.9579\n",
            "Epoch [2/3], Step [3800/12500], Loss: 3.0916\n",
            "Epoch [2/3], Step [3900/12500], Loss: 1.3659\n",
            "Epoch [2/3], Step [4000/12500], Loss: 0.3840\n",
            "Epoch [2/3], Step [4100/12500], Loss: 1.2152\n",
            "Epoch [2/3], Step [4200/12500], Loss: 0.7125\n",
            "Epoch [2/3], Step [4300/12500], Loss: 0.8416\n",
            "Epoch [2/3], Step [4400/12500], Loss: 2.0653\n",
            "Epoch [2/3], Step [4500/12500], Loss: 0.5876\n",
            "Epoch [2/3], Step [4600/12500], Loss: 1.7584\n",
            "Epoch [2/3], Step [4700/12500], Loss: 1.9625\n",
            "Epoch [2/3], Step [4800/12500], Loss: 0.9566\n",
            "Epoch [2/3], Step [4900/12500], Loss: 1.4191\n",
            "Epoch [2/3], Step [5000/12500], Loss: 1.5722\n",
            "Epoch [2/3], Step [5100/12500], Loss: 2.2219\n",
            "Epoch [2/3], Step [5200/12500], Loss: 2.0210\n",
            "Epoch [2/3], Step [5300/12500], Loss: 1.7230\n",
            "Epoch [2/3], Step [5400/12500], Loss: 1.4449\n",
            "Epoch [2/3], Step [5500/12500], Loss: 1.9917\n",
            "Epoch [2/3], Step [5600/12500], Loss: 1.5818\n",
            "Epoch [2/3], Step [5700/12500], Loss: 1.2418\n",
            "Epoch [2/3], Step [5800/12500], Loss: 1.5368\n",
            "Epoch [2/3], Step [5900/12500], Loss: 0.7896\n",
            "Epoch [2/3], Step [6000/12500], Loss: 2.3437\n",
            "Epoch [2/3], Step [6100/12500], Loss: 1.4185\n",
            "Epoch [2/3], Step [6200/12500], Loss: 0.7418\n",
            "Epoch [2/3], Step [6300/12500], Loss: 0.6997\n",
            "Epoch [2/3], Step [6400/12500], Loss: 1.5890\n",
            "Epoch [2/3], Step [6500/12500], Loss: 0.8783\n",
            "Epoch [2/3], Step [6600/12500], Loss: 1.1238\n",
            "Epoch [2/3], Step [6700/12500], Loss: 1.4411\n",
            "Epoch [2/3], Step [6800/12500], Loss: 0.6407\n",
            "Epoch [2/3], Step [6900/12500], Loss: 1.2921\n",
            "Epoch [2/3], Step [7000/12500], Loss: 2.7276\n",
            "Epoch [2/3], Step [7100/12500], Loss: 1.6466\n",
            "Epoch [2/3], Step [7200/12500], Loss: 0.8739\n",
            "Epoch [2/3], Step [7300/12500], Loss: 1.2899\n",
            "Epoch [2/3], Step [7400/12500], Loss: 0.9611\n",
            "Epoch [2/3], Step [7500/12500], Loss: 0.8161\n",
            "Epoch [2/3], Step [7600/12500], Loss: 1.0435\n",
            "Epoch [2/3], Step [7700/12500], Loss: 1.4884\n",
            "Epoch [2/3], Step [7800/12500], Loss: 1.7556\n",
            "Epoch [2/3], Step [7900/12500], Loss: 0.6870\n",
            "Epoch [2/3], Step [8000/12500], Loss: 0.8575\n",
            "Epoch [2/3], Step [8100/12500], Loss: 1.7339\n",
            "Epoch [2/3], Step [8200/12500], Loss: 1.5507\n",
            "Epoch [2/3], Step [8300/12500], Loss: 2.6498\n",
            "Epoch [2/3], Step [8400/12500], Loss: 1.4828\n",
            "Epoch [2/3], Step [8500/12500], Loss: 1.2722\n",
            "Epoch [2/3], Step [8600/12500], Loss: 0.7182\n",
            "Epoch [2/3], Step [8700/12500], Loss: 0.8623\n",
            "Epoch [2/3], Step [8800/12500], Loss: 0.9290\n",
            "Epoch [2/3], Step [8900/12500], Loss: 1.5316\n",
            "Epoch [2/3], Step [9000/12500], Loss: 0.7993\n",
            "Epoch [2/3], Step [9100/12500], Loss: 1.1718\n",
            "Epoch [2/3], Step [9200/12500], Loss: 0.7456\n",
            "Epoch [2/3], Step [9300/12500], Loss: 1.4235\n",
            "Epoch [2/3], Step [9400/12500], Loss: 0.6453\n",
            "Epoch [2/3], Step [9500/12500], Loss: 1.9744\n",
            "Epoch [2/3], Step [9600/12500], Loss: 2.0984\n",
            "Epoch [2/3], Step [9700/12500], Loss: 1.1635\n",
            "Epoch [2/3], Step [9800/12500], Loss: 0.7315\n",
            "Epoch [2/3], Step [9900/12500], Loss: 0.3343\n",
            "Epoch [2/3], Step [10000/12500], Loss: 0.7235\n",
            "Epoch [2/3], Step [10100/12500], Loss: 2.1041\n",
            "Epoch [2/3], Step [10200/12500], Loss: 1.2113\n",
            "Epoch [2/3], Step [10300/12500], Loss: 2.6196\n",
            "Epoch [2/3], Step [10400/12500], Loss: 0.7074\n",
            "Epoch [2/3], Step [10500/12500], Loss: 0.9056\n",
            "Epoch [2/3], Step [10600/12500], Loss: 0.7065\n",
            "Epoch [2/3], Step [10700/12500], Loss: 1.6982\n",
            "Epoch [2/3], Step [10800/12500], Loss: 1.5367\n",
            "Epoch [2/3], Step [10900/12500], Loss: 1.0830\n",
            "Epoch [2/3], Step [11000/12500], Loss: 1.7363\n",
            "Epoch [2/3], Step [11100/12500], Loss: 0.7154\n",
            "Epoch [2/3], Step [11200/12500], Loss: 1.1931\n",
            "Epoch [2/3], Step [11300/12500], Loss: 0.8679\n",
            "Epoch [2/3], Step [11400/12500], Loss: 0.9550\n",
            "Epoch [2/3], Step [11500/12500], Loss: 0.9283\n",
            "Epoch [2/3], Step [11600/12500], Loss: 1.3752\n",
            "Epoch [2/3], Step [11700/12500], Loss: 1.4853\n",
            "Epoch [2/3], Step [11800/12500], Loss: 1.9571\n",
            "Epoch [2/3], Step [11900/12500], Loss: 0.8850\n",
            "Epoch [2/3], Step [12000/12500], Loss: 0.3772\n",
            "Epoch [2/3], Step [12100/12500], Loss: 1.2033\n",
            "Epoch [2/3], Step [12200/12500], Loss: 0.6274\n",
            "Epoch [2/3], Step [12300/12500], Loss: 0.7531\n",
            "Epoch [2/3], Step [12400/12500], Loss: 1.1686\n",
            "Epoch [2/3], Step [12500/12500], Loss: 1.4398\n",
            "Epoch [3/3], Step [100/12500], Loss: 1.3600\n",
            "Epoch [3/3], Step [200/12500], Loss: 1.3066\n",
            "Epoch [3/3], Step [300/12500], Loss: 0.8687\n",
            "Epoch [3/3], Step [400/12500], Loss: 0.9535\n",
            "Epoch [3/3], Step [500/12500], Loss: 0.7352\n",
            "Epoch [3/3], Step [600/12500], Loss: 0.6368\n",
            "Epoch [3/3], Step [700/12500], Loss: 1.4215\n",
            "Epoch [3/3], Step [800/12500], Loss: 1.2095\n",
            "Epoch [3/3], Step [900/12500], Loss: 0.6816\n",
            "Epoch [3/3], Step [1000/12500], Loss: 1.2565\n",
            "Epoch [3/3], Step [1100/12500], Loss: 0.9861\n",
            "Epoch [3/3], Step [1200/12500], Loss: 0.8227\n",
            "Epoch [3/3], Step [1300/12500], Loss: 1.3286\n",
            "Epoch [3/3], Step [1400/12500], Loss: 1.4843\n",
            "Epoch [3/3], Step [1500/12500], Loss: 1.6457\n",
            "Epoch [3/3], Step [1600/12500], Loss: 1.8004\n",
            "Epoch [3/3], Step [1700/12500], Loss: 1.7021\n",
            "Epoch [3/3], Step [1800/12500], Loss: 2.0440\n",
            "Epoch [3/3], Step [1900/12500], Loss: 0.9790\n",
            "Epoch [3/3], Step [2000/12500], Loss: 0.2820\n",
            "Epoch [3/3], Step [2100/12500], Loss: 1.3768\n",
            "Epoch [3/3], Step [2200/12500], Loss: 1.0635\n",
            "Epoch [3/3], Step [2300/12500], Loss: 2.1457\n",
            "Epoch [3/3], Step [2400/12500], Loss: 1.8125\n",
            "Epoch [3/3], Step [2500/12500], Loss: 1.0258\n",
            "Epoch [3/3], Step [2600/12500], Loss: 2.5549\n",
            "Epoch [3/3], Step [2700/12500], Loss: 0.9906\n",
            "Epoch [3/3], Step [2800/12500], Loss: 1.0758\n",
            "Epoch [3/3], Step [2900/12500], Loss: 1.4421\n",
            "Epoch [3/3], Step [3000/12500], Loss: 1.2617\n",
            "Epoch [3/3], Step [3100/12500], Loss: 1.2081\n",
            "Epoch [3/3], Step [3200/12500], Loss: 2.4478\n",
            "Epoch [3/3], Step [3300/12500], Loss: 1.2410\n",
            "Epoch [3/3], Step [3400/12500], Loss: 0.5569\n",
            "Epoch [3/3], Step [3500/12500], Loss: 1.0066\n",
            "Epoch [3/3], Step [3600/12500], Loss: 0.5581\n",
            "Epoch [3/3], Step [3700/12500], Loss: 2.4654\n",
            "Epoch [3/3], Step [3800/12500], Loss: 1.1701\n",
            "Epoch [3/3], Step [3900/12500], Loss: 1.9893\n",
            "Epoch [3/3], Step [4000/12500], Loss: 0.9406\n",
            "Epoch [3/3], Step [4100/12500], Loss: 1.0024\n",
            "Epoch [3/3], Step [4200/12500], Loss: 0.6531\n",
            "Epoch [3/3], Step [4300/12500], Loss: 1.2219\n",
            "Epoch [3/3], Step [4400/12500], Loss: 1.8068\n",
            "Epoch [3/3], Step [4500/12500], Loss: 0.6094\n",
            "Epoch [3/3], Step [4600/12500], Loss: 1.2302\n",
            "Epoch [3/3], Step [4700/12500], Loss: 1.4598\n",
            "Epoch [3/3], Step [4800/12500], Loss: 1.7849\n",
            "Epoch [3/3], Step [4900/12500], Loss: 1.2895\n",
            "Epoch [3/3], Step [5000/12500], Loss: 0.6275\n",
            "Epoch [3/3], Step [5100/12500], Loss: 1.1182\n",
            "Epoch [3/3], Step [5200/12500], Loss: 1.2879\n",
            "Epoch [3/3], Step [5300/12500], Loss: 1.1084\n",
            "Epoch [3/3], Step [5400/12500], Loss: 0.8789\n",
            "Epoch [3/3], Step [5500/12500], Loss: 1.5476\n",
            "Epoch [3/3], Step [5600/12500], Loss: 0.8944\n",
            "Epoch [3/3], Step [5700/12500], Loss: 1.0197\n",
            "Epoch [3/3], Step [5800/12500], Loss: 1.3416\n",
            "Epoch [3/3], Step [5900/12500], Loss: 1.1078\n",
            "Epoch [3/3], Step [6000/12500], Loss: 0.4319\n",
            "Epoch [3/3], Step [6100/12500], Loss: 1.3763\n",
            "Epoch [3/3], Step [6200/12500], Loss: 1.2464\n",
            "Epoch [3/3], Step [6300/12500], Loss: 1.1167\n",
            "Epoch [3/3], Step [6400/12500], Loss: 1.1052\n",
            "Epoch [3/3], Step [6500/12500], Loss: 1.0276\n",
            "Epoch [3/3], Step [6600/12500], Loss: 1.1830\n",
            "Epoch [3/3], Step [6700/12500], Loss: 1.4240\n",
            "Epoch [3/3], Step [6800/12500], Loss: 1.4829\n",
            "Epoch [3/3], Step [6900/12500], Loss: 0.9551\n",
            "Epoch [3/3], Step [7000/12500], Loss: 1.3274\n",
            "Epoch [3/3], Step [7100/12500], Loss: 0.6295\n",
            "Epoch [3/3], Step [7200/12500], Loss: 1.0380\n",
            "Epoch [3/3], Step [7300/12500], Loss: 0.7930\n",
            "Epoch [3/3], Step [7400/12500], Loss: 1.3680\n",
            "Epoch [3/3], Step [7500/12500], Loss: 1.8499\n",
            "Epoch [3/3], Step [7600/12500], Loss: 1.3435\n",
            "Epoch [3/3], Step [7700/12500], Loss: 1.5093\n",
            "Epoch [3/3], Step [7800/12500], Loss: 1.5689\n",
            "Epoch [3/3], Step [7900/12500], Loss: 1.0592\n",
            "Epoch [3/3], Step [8000/12500], Loss: 0.9019\n",
            "Epoch [3/3], Step [8100/12500], Loss: 0.6950\n",
            "Epoch [3/3], Step [8200/12500], Loss: 1.7065\n",
            "Epoch [3/3], Step [8300/12500], Loss: 1.2315\n",
            "Epoch [3/3], Step [8400/12500], Loss: 1.8976\n",
            "Epoch [3/3], Step [8500/12500], Loss: 1.4302\n",
            "Epoch [3/3], Step [8600/12500], Loss: 0.8785\n",
            "Epoch [3/3], Step [8700/12500], Loss: 2.3021\n",
            "Epoch [3/3], Step [8800/12500], Loss: 0.6510\n",
            "Epoch [3/3], Step [8900/12500], Loss: 0.6864\n",
            "Epoch [3/3], Step [9000/12500], Loss: 1.1528\n",
            "Epoch [3/3], Step [9100/12500], Loss: 1.0987\n",
            "Epoch [3/3], Step [9200/12500], Loss: 1.1429\n",
            "Epoch [3/3], Step [9300/12500], Loss: 0.2605\n",
            "Epoch [3/3], Step [9400/12500], Loss: 0.8812\n",
            "Epoch [3/3], Step [9500/12500], Loss: 2.1155\n",
            "Epoch [3/3], Step [9600/12500], Loss: 0.1706\n",
            "Epoch [3/3], Step [9700/12500], Loss: 0.6723\n",
            "Epoch [3/3], Step [9800/12500], Loss: 1.7185\n",
            "Epoch [3/3], Step [9900/12500], Loss: 0.8711\n",
            "Epoch [3/3], Step [10000/12500], Loss: 1.5150\n",
            "Epoch [3/3], Step [10100/12500], Loss: 0.7419\n",
            "Epoch [3/3], Step [10200/12500], Loss: 0.2812\n",
            "Epoch [3/3], Step [10300/12500], Loss: 1.6443\n",
            "Epoch [3/3], Step [10400/12500], Loss: 2.1016\n",
            "Epoch [3/3], Step [10500/12500], Loss: 1.1339\n",
            "Epoch [3/3], Step [10600/12500], Loss: 1.6677\n",
            "Epoch [3/3], Step [10700/12500], Loss: 1.3253\n",
            "Epoch [3/3], Step [10800/12500], Loss: 1.2813\n",
            "Epoch [3/3], Step [10900/12500], Loss: 0.6513\n",
            "Epoch [3/3], Step [11000/12500], Loss: 1.5050\n",
            "Epoch [3/3], Step [11100/12500], Loss: 0.6666\n",
            "Epoch [3/3], Step [11200/12500], Loss: 0.3229\n",
            "Epoch [3/3], Step [11300/12500], Loss: 1.7250\n",
            "Epoch [3/3], Step [11400/12500], Loss: 0.7340\n",
            "Epoch [3/3], Step [11500/12500], Loss: 0.5854\n",
            "Epoch [3/3], Step [11600/12500], Loss: 1.2928\n",
            "Epoch [3/3], Step [11700/12500], Loss: 0.9630\n",
            "Epoch [3/3], Step [11800/12500], Loss: 1.2513\n",
            "Epoch [3/3], Step [11900/12500], Loss: 0.5236\n",
            "Epoch [3/3], Step [12000/12500], Loss: 0.7366\n",
            "Epoch [3/3], Step [12100/12500], Loss: 1.7932\n",
            "Epoch [3/3], Step [12200/12500], Loss: 0.7550\n",
            "Epoch [3/3], Step [12300/12500], Loss: 0.3519\n",
            "Epoch [3/3], Step [12400/12500], Loss: 0.8479\n",
            "Epoch [3/3], Step [12500/12500], Loss: 2.4674\n",
            "Accuracy of the network on the 10000 test images: 58.28 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hasil akurasi berdasarkan tutorial PyTorch adalah 58.28%; lebih baik daripada tutorial tersebut karena ada penambahan epoch dari 2 menjadi 3. Penambahan epoch itu pula meningkatkan akurasi model."
      ],
      "metadata": {
        "id": "aO79LPtQphix"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Simpan model\n",
        "\n",
        "Sesuai arahan tutorial PyTorch dan junjey"
      ],
      "metadata": {
        "id": "-GCMeAw9hlGS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MNIST_PATH = './mnist_net.pth'\n",
        "torch.save(mnist_model.state_dict(), MNIST_PATH)"
      ],
      "metadata": {
        "id": "fz7102_AmLIN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CIFAR_PATH = './cifar_net.pth'\n",
        "torch.save(cifar_model.state_dict(), CIFAR_PATH)"
      ],
      "metadata": {
        "id": "_IcInDR3Y2k6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}