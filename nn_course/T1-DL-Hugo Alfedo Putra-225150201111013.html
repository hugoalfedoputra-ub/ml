<!DOCTYPE html>
<html>
<head>
<title>T1-DL-Hugo Alfedo Putra-225150201111013.md</title>
<meta http-equiv="Content-type" content="text/html;charset=UTF-8">

<style>
/* https://github.com/microsoft/vscode/blob/master/extensions/markdown-language-features/media/markdown.css */
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

body {
	font-family: var(--vscode-markdown-font-family, -apple-system, BlinkMacSystemFont, "Segoe WPC", "Segoe UI", "Ubuntu", "Droid Sans", sans-serif);
	font-size: var(--vscode-markdown-font-size, 14px);
	padding: 0 26px;
	line-height: var(--vscode-markdown-line-height, 22px);
	word-wrap: break-word;
}

#code-csp-warning {
	position: fixed;
	top: 0;
	right: 0;
	color: white;
	margin: 16px;
	text-align: center;
	font-size: 12px;
	font-family: sans-serif;
	background-color:#444444;
	cursor: pointer;
	padding: 6px;
	box-shadow: 1px 1px 1px rgba(0,0,0,.25);
}

#code-csp-warning:hover {
	text-decoration: none;
	background-color:#007acc;
	box-shadow: 2px 2px 2px rgba(0,0,0,.25);
}

body.scrollBeyondLastLine {
	margin-bottom: calc(100vh - 22px);
}

body.showEditorSelection .code-line {
	position: relative;
}

body.showEditorSelection .code-active-line:before,
body.showEditorSelection .code-line:hover:before {
	content: "";
	display: block;
	position: absolute;
	top: 0;
	left: -12px;
	height: 100%;
}

body.showEditorSelection li.code-active-line:before,
body.showEditorSelection li.code-line:hover:before {
	left: -30px;
}

.vscode-light.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(0, 0, 0, 0.15);
}

.vscode-light.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(0, 0, 0, 0.40);
}

.vscode-light.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

.vscode-dark.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(255, 255, 255, 0.4);
}

.vscode-dark.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(255, 255, 255, 0.60);
}

.vscode-dark.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

.vscode-high-contrast.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(255, 160, 0, 0.7);
}

.vscode-high-contrast.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(255, 160, 0, 1);
}

.vscode-high-contrast.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

img {
	max-width: 100%;
	max-height: 100%;
}

a {
	text-decoration: none;
}

a:hover {
	text-decoration: underline;
}

a:focus,
input:focus,
select:focus,
textarea:focus {
	outline: 1px solid -webkit-focus-ring-color;
	outline-offset: -1px;
}

hr {
	border: 0;
	height: 2px;
	border-bottom: 2px solid;
}

h1 {
	padding-bottom: 0.3em;
	line-height: 1.2;
	border-bottom-width: 1px;
	border-bottom-style: solid;
}

h1, h2, h3 {
	font-weight: normal;
}

table {
	border-collapse: collapse;
}

table > thead > tr > th {
	text-align: left;
	border-bottom: 1px solid;
}

table > thead > tr > th,
table > thead > tr > td,
table > tbody > tr > th,
table > tbody > tr > td {
	padding: 5px 10px;
}

table > tbody > tr + tr > td {
	border-top: 1px solid;
}

blockquote {
	margin: 0 7px 0 5px;
	padding: 0 16px 0 10px;
	border-left-width: 5px;
	border-left-style: solid;
}

code {
	font-family: Menlo, Monaco, Consolas, "Droid Sans Mono", "Courier New", monospace, "Droid Sans Fallback";
	font-size: 1em;
	line-height: 1.357em;
}

body.wordWrap pre {
	white-space: pre-wrap;
}

pre:not(.hljs),
pre.hljs code > div {
	padding: 16px;
	border-radius: 3px;
	overflow: auto;
}

pre code {
	color: var(--vscode-editor-foreground);
	tab-size: 4;
}

/** Theming */

.vscode-light pre {
	background-color: rgba(220, 220, 220, 0.4);
}

.vscode-dark pre {
	background-color: rgba(10, 10, 10, 0.4);
}

.vscode-high-contrast pre {
	background-color: rgb(0, 0, 0);
}

.vscode-high-contrast h1 {
	border-color: rgb(0, 0, 0);
}

.vscode-light table > thead > tr > th {
	border-color: rgba(0, 0, 0, 0.69);
}

.vscode-dark table > thead > tr > th {
	border-color: rgba(255, 255, 255, 0.69);
}

.vscode-light h1,
.vscode-light hr,
.vscode-light table > tbody > tr + tr > td {
	border-color: rgba(0, 0, 0, 0.18);
}

.vscode-dark h1,
.vscode-dark hr,
.vscode-dark table > tbody > tr + tr > td {
	border-color: rgba(255, 255, 255, 0.18);
}

</style>

<style>
/* Tomorrow Theme */
/* http://jmblog.github.com/color-themes-for-google-code-highlightjs */
/* Original theme - https://github.com/chriskempson/tomorrow-theme */

/* Tomorrow Comment */
.hljs-comment,
.hljs-quote {
	color: #8e908c;
}

/* Tomorrow Red */
.hljs-variable,
.hljs-template-variable,
.hljs-tag,
.hljs-name,
.hljs-selector-id,
.hljs-selector-class,
.hljs-regexp,
.hljs-deletion {
	color: #c82829;
}

/* Tomorrow Orange */
.hljs-number,
.hljs-built_in,
.hljs-builtin-name,
.hljs-literal,
.hljs-type,
.hljs-params,
.hljs-meta,
.hljs-link {
	color: #f5871f;
}

/* Tomorrow Yellow */
.hljs-attribute {
	color: #eab700;
}

/* Tomorrow Green */
.hljs-string,
.hljs-symbol,
.hljs-bullet,
.hljs-addition {
	color: #718c00;
}

/* Tomorrow Blue */
.hljs-title,
.hljs-section {
	color: #4271ae;
}

/* Tomorrow Purple */
.hljs-keyword,
.hljs-selector-tag {
	color: #8959a8;
}

.hljs {
	display: block;
	overflow-x: auto;
	color: #4d4d4c;
	padding: 0.5em;
}

.hljs-emphasis {
	font-style: italic;
}

.hljs-strong {
	font-weight: bold;
}
</style>

<style>
/*
 * Markdown PDF CSS
 */

 body {
	font-family: -apple-system, BlinkMacSystemFont, "Segoe WPC", "Segoe UI", "Ubuntu", "Droid Sans", sans-serif, "Meiryo";
	padding: 0 12px;
}

pre {
	background-color: #f8f8f8;
	border: 1px solid #cccccc;
	border-radius: 3px;
	overflow-x: auto;
	white-space: pre-wrap;
	overflow-wrap: break-word;
}

pre:not(.hljs) {
	padding: 23px;
	line-height: 19px;
}

blockquote {
	background: rgba(127, 127, 127, 0.1);
	border-color: rgba(0, 122, 204, 0.5);
}

.emoji {
	height: 1.4em;
}

code {
	font-size: 14px;
	line-height: 19px;
}

/* for inline code */
:not(pre):not(.hljs) > code {
	color: #C9AE75; /* Change the old color so it seems less like an error */
	font-size: inherit;
}

/* Page Break : use <div class="page"/> to insert page break
-------------------------------------------------------- */
.page {
	page-break-after: always;
}

</style>

<script src="https://unpkg.com/mermaid/dist/mermaid.min.js"></script>
</head>
<body>
  <script>
    mermaid.initialize({
      startOnLoad: true,
      theme: document.body.classList.contains('vscode-dark') || document.body.classList.contains('vscode-high-contrast')
          ? 'dark'
          : 'default'
    });
  </script>
<table border style="width: 100%">
	<tr>
		<td>Nama</td>
		<td>Hugo Alfedo Putra</td>
		<td>NIM</td>
		<td>225150201111013</td>
	</tr>
	<tr>
		<td>Kelas</td>
		<td>DL-B</td>
		<td>Tanggal Tugas</td>
		<td>3 September 2024</td>
	</tr>
	<tr>
		<td colspan=2>Judul Tugas</td>
		<td colspan=2>Backpropagation Menggunakan PyTorch</td>
	</tr>
</table>
<br>
<p>Laporan ini ditulis sesuai dengan urutan kemunculan cuplikan-cuplikan kode pada <a href="https://github.com/yunjey/pytorch-tutorial/blob/master/tutorials/01-basics/feedforward_neural_network/main.py">contoh feed-forward neural-network PyTorch oleh junjey</a>.</p>
<h1 id="pengaturan-hyper-parameter">Pengaturan Hyper-parameter</h1>
<pre class="hljs"><code><div><span class="hljs-comment"># Hyper-parameters</span>
input_size = <span class="hljs-number">784</span>
hidden_size = <span class="hljs-number">500</span>
num_classes = <span class="hljs-number">10</span>
num_epochs = <span class="hljs-number">5</span>
batch_size = <span class="hljs-number">100</span>
learning_rate = <span class="hljs-number">0.001</span>
</div></code></pre>
<p>Cuplikan di atas menunjukkan enam hyper-parameter yang digunakan, yaitu:</p>
<ol>
<li><code>input_size</code>: banyak neuron input pada jaringan. Perlu diketahui, berdasarkan LeCun pada <a href="https://yann.lecun.com/exdb/mnist/">situs ini</a>:</li>
</ol>
<pre class="hljs"><code><div>.... the images were centered in a 28x28 image by computing the center of mass of the pixels, ...
</div></code></pre>
<p>bahwa gambar-gambar pada dataset MNIST memiliki ukuran 28 pixel kali 28 pixel, sehingga tiap neuron input berupa tiap pixel ($28\text{px}\times 28\text{px}=784\text{px}$) pada gambar dari dataset tersebut.</p>
<ol start="2">
<li><code>hidden_size</code>: banyak neuron pada satu lapisan tersembunyi pada jaringan</li>
<li><code>num_classes</code>: banyak kelas kategori yang akan diklasifikasikan oleh jaringan; bernilai 10 karena dataset gambar berupa tiap digit dari 0 hingga 9</li>
<li><code>num_epochs</code>: di mana epoch sendiri berarti satu putaran pada dataset; sehingga <code>num_epochs</code> berarti banyak putaran pada dataset yang akan dilakukan saat proses training</li>
<li><code>batch_size</code>: besar sample dari dataset yang akan digunakan dalam satu iterasi dalam satu epoch, di mana dari hasil:</li>
</ol>
<pre class="hljs"><code><div>print(<span class="hljs-string">'Train dataset size: '</span>, len(train_dataset))
print(<span class="hljs-string">'test dataset size: '</span>, len(test_dataset))
print(<span class="hljs-string">'Loaded train size: '</span>, len(train_loader))
print(<span class="hljs-string">'Loaded test size: '</span>, len(test_loader))

Train dataset size:  <span class="hljs-number">60000</span>
test dataset size:  <span class="hljs-number">10000</span>
Loaded train size:  <span class="hljs-number">600</span>
Loaded test size:  <span class="hljs-number">100</span>
</div></code></pre>
<p>terlihat bahwa <code>batch_size = 100</code> berarti akan terdapat (dalam kasus dataset training) $60000\div 100 = 600$ iterasi di mana tiap iterasi berisi 100 sample dari dataset.</p>
<ol start="6">
<li><code>learning_rate</code>: seberapa besar (atau jauh) bobot akan berubah setelah jaringan melalui optimasi untuk meminimalisir loss</li>
</ol>
<h2 id="deklarasi-hyper-parameter-untuk-eksperimen">Deklarasi Hyper-parameter untuk Eksperimen</h2>
<pre class="hljs"><code><div><span class="hljs-comment"># Hyper-parameters</span>
input_size = <span class="hljs-number">784</span> // tetap sama
hidden_size = [<span class="hljs-number">400</span>, <span class="hljs-number">500</span>, <span class="hljs-number">600</span>]
hidden_layers = [<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>]
num_classes = <span class="hljs-number">10</span> // tetap sama
num_epochs = range(<span class="hljs-number">3</span>,<span class="hljs-number">9</span>,<span class="hljs-number">1</span>) // <span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>, <span class="hljs-number">6</span>, <span class="hljs-number">7</span>, <span class="hljs-number">8</span>
batch_size = [<span class="hljs-number">100</span>, <span class="hljs-number">300</span>, <span class="hljs-number">600</span>]
learning_rate = [<span class="hljs-number">10e-1</span>, <span class="hljs-number">10e-3</span>, <span class="hljs-number">10e-5</span>, <span class="hljs-number">10e-7</span>]
</div></code></pre>
<h1 id="arsitektur-jaringan">Arsitektur Jaringan</h1>
<pre class="hljs"><code><div><span class="hljs-comment"># Fully connected neural network with one hidden layer</span>
<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">NeuralNet</span><span class="hljs-params">(nn.Module)</span>:</span>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self, input_size, hidden_size, num_classes)</span>:</span>
        super(NeuralNet, self).__init__()
        self.fc1 = nn.Linear(input_size, hidden_size)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(hidden_size, num_classes)

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span><span class="hljs-params">(self, x)</span>:</span>
        out = self.fc1(x)
        out = self.relu(out)
        out = self.fc2(out)
        <span class="hljs-keyword">return</span> out

model = NeuralNet(input_size, hidden_size, num_classes).to(device)
</div></code></pre>
<p>Pertama, <code>class NeuralNet(nn.Module)</code> merupakan deklarasi kelas <code>NeuralNet</code> yang meng-extend kelas nn.Module milik PyTorch, sebagaimana pula direkomendasikan dalam <a href="https://pytorch.org/tutorials/recipes/recipes/defining_a_neural_network.html">dokumentasi PyTorch sendiri</a>.</p>
<pre class="hljs"><code><div>self.fc1 = nn.Linear(input_size, hidden_size)
self.relu = nn.ReLU()
self.fc2 = nn.Linear(hidden_size, num_classes)
</div></code></pre>
<p>merupakan arsitektur jaringan <code>NeuralNet</code> yang terdiri dari dua lapisan berupa Fully Connected (FC) layer yang mengapit fungsi aktivasi ReLU (Rectified Linear Unit). FC layer sendiri berarti tiap neuron input memetakan ke tiap output neuron (M:N). Fungsi aktivasi ReLU sendiri didefinisikan:
$$\text{ReLU}(x)=\max(0,x)=\frac{x+|x|}{2}$$</p>
<h1 id="forward-pass">Forward Pass</h1>
<pre class="hljs"><code><div><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span><span class="hljs-params">(self, x)</span>:</span>
    out = self.fc1(x)
    out = self.relu(out)
    out = self.fc2(out)
    <span class="hljs-keyword">return</span> out
</div></code></pre>
<p>merupakan fungsi milik kelas <code>NeuralNet</code> bernama <code>forward</code> yang merupakan forward-pass pada jaringan. Tahapan forward-pass dirincikan:</p>
<ol>
<li>Variabel <code>out</code> pertama merupakan weighted sum (matriks $784\times1$) dari FC layer pertama,</li>
<li>Variabel <code>out</code> kedua menerapkan fungsi aktivasi ReLU pada tiap baris pada matriks weighted sum, lalu</li>
<li>Variabel <code>out</code> terakhir mengembalikan weighted sum (matriks $500\times1$) dari FC layer kedua yang kemudian di-<code>return</code>.</li>
</ol>
<p>Nantinya pada kode, forward pass dilakukan pada</p>
<pre class="hljs"><code><div><span class="hljs-comment"># Forward pass</span>
outputs = model(images)
loss = criterion(outputs, labels)
</div></code></pre>
<p>saat melatih model.</p>
<h1 id="instansiasi-jaringan">Instansiasi Jaringan</h1>
<pre class="hljs"><code><div>model = NeuralNet(input_size, hidden_size, num_classes).to(device)
</div></code></pre>
<h1 id="penghitungan-loss">Penghitungan Loss</h1>
<p>Seperti pada</p>
<pre class="hljs"><code><div>criterion = nn.CrossEntropyLoss()
</div></code></pre>
<p>di mana jaringan menggunakan <a href="https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html">Cross Entropy Loss</a> yang berfungsi dengan menghitung perbedaan distribusi probabilitas antara model dan prediksinya (Sumber: <a href="https://www.datacamp.com/tutorial/the-cross-entropy-loss-function-in-machine-learning">Datacamp</a>).</p>
<h2 id="optimasi">Optimasi</h2>
<p>Seperti pada</p>
<pre class="hljs"><code><div>optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)
</div></code></pre>
<p>di mana jaringan menggunakan optimasi ADAM (Adaptive Moment Estimation) yang akan mengatur nilai <code>learning_rate</code> secara dinamis agar nilai tersebut mengalami perubahan besar saat di awal dan mengecil (secara eksponensial) di akhir (Sumber: <a href="https://www.geeksforgeeks.org/adam-optimizer/">GeeksForGeeks</a>).</p>
<h2 id="implementasi-fungsi-aktivasi-lain">Implementasi Fungsi Aktivasi Lain</h2>
<p>Digunakan fungsi aktivasi lain berupa:</p>
<ul>
<li>Untuk hidden layer: LeakyReLU untuk menghindari permasalahan pada ReLU di mana saat weighted sum $\leq$ 0 akan menyebabkan neuron itu mati atau hanya bernilai 0.</li>
<li>Untuk output layer: Softmax untuk menghasilkan distribusi probabilitas sebagai input Cross Entropy Loss.</li>
</ul>
<h1 id="melatih-model">Melatih Model</h1>
<pre class="hljs"><code><div><span class="hljs-comment"># Train the model</span>
total_step = len(train_loader)
<span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> range(num_epochs):
    <span class="hljs-keyword">for</span> i, (images, labels) <span class="hljs-keyword">in</span> enumerate(train_loader):
        <span class="hljs-comment"># Move tensors to the configured device</span>
        images = images.reshape(<span class="hljs-number">-1</span>, <span class="hljs-number">28</span>*<span class="hljs-number">28</span>).to(device)
        labels = labels.to(device)
        ...
</div></code></pre>
<p>Pada cuplikan di atas terlihat dalam pelatihan model, tiap gambar (dalam kasus ini berupa tensor 2D $28\times28$) diubah menjadi tensor 1D dengan panjang 784 (sama dengan <code>28*28</code>) pada <code>images = images.reshape(-1, 28*28).to(device)</code> khususnya dengan argumen <code>-1</code> pada <code>reshape(-1, ...</code>. Tiap label juga diteruskan ke device atau ke jaringan dengan <code>labels = labels.to(device)</code>.</p>
<h1 id="backward-pass">Backward Pass</h1>
<pre class="hljs"><code><div><span class="hljs-comment"># Backward and optimize</span>
optimizer.zero_grad()
loss.backward()
optimizer.step()

<span class="hljs-keyword">if</span> (i+<span class="hljs-number">1</span>) % <span class="hljs-number">100</span> == <span class="hljs-number">0</span>:
    <span class="hljs-keyword">print</span> (<span class="hljs-string">'Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'</span>
            .format(epoch+<span class="hljs-number">1</span>, num_epochs, i+<span class="hljs-number">1</span>, total_step, loss.item()))
</div></code></pre>
<p>Pada cuplikan di atas terlihat optimasi dan backpropagation (backward pass). Mulanya, nilai-nilai gradien dibuat <code>null</code> (berdasarkan <a href="https://pytorch.org/docs/stable/generated/torch.optim.Optimizer.zero_grad.html">docs ini</a>) yang kemudian dihitung loss-nya dan kemudian dilakukan backpropagation dengan <code>loss.backward()</code>. Terakhir dilakukan <code>optimizer.step()</code> untuk melakukan satu step optimasi (berdasarkan <a href="https://pytorch.org/docs/stable/generated/torch.optim.Optimizer.step.html">docs ini</a>). Hanya tiap 100 step akan di-print ke console beserta nilai loss-nya sebagaimana terlihat pada</p>
<pre class="hljs"><code><div>Epoch [<span class="hljs-number">1</span>/<span class="hljs-number">5</span>], Step [<span class="hljs-number">100</span>/<span class="hljs-number">600</span>], Loss: <span class="hljs-number">0.3124</span>
Epoch [<span class="hljs-number">1</span>/<span class="hljs-number">5</span>], Step [<span class="hljs-number">200</span>/<span class="hljs-number">600</span>], Loss: <span class="hljs-number">0.1915</span>
Epoch [<span class="hljs-number">1</span>/<span class="hljs-number">5</span>], Step [<span class="hljs-number">300</span>/<span class="hljs-number">600</span>], Loss: <span class="hljs-number">0.2400</span>
...
</div></code></pre>
<h1 id="hasil-eksperimen">Hasil Eksperimen</h1>
<h2 id="visualisasi-loss">Visualisasi Loss</h2>
<h2 id="akurasi">Akurasi</h2>
<h2 id="konvergensi-model">Konvergensi Model</h2>

</body>
</html>
